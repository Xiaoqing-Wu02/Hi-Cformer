{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§¬ Embedding with Hi-Cformer on Wu2024 Dataset\n",
    "\n",
    "This notebook demonstrates how to train the **Hi-Cformer** model on single-cell Hi-C data, using per-chromosome sparse contact matrices as input.  \n",
    "The model learns **cell embeddings**, supporting downstream tasks such as visualization.\n",
    "\n",
    "\n",
    "\n",
    "## ðŸ“ Input Files\n",
    "\n",
    "### ðŸ”¹ 1. Sparse Contact Matrix Folder\n",
    "\n",
    "Each `.npy` file contains a **sparse adjacency matrix** for one chromosome.  \n",
    "These matrices are typically saved in coordinate (COO) or compressed sparse row (CSR) format.\n",
    "\n",
    "**Example path:**\n",
    "\n",
    "```\n",
    "/home/scHi-C_dataset/Wu2024_GSE240128/raw/\n",
    "```\n",
    "\n",
    "**Example contents:**\n",
    "\n",
    "- `chr1_sparse_adj.npy`  \n",
    "- `chr2_sparse_adj.npy`  \n",
    "- ...\n",
    "\n",
    "Each matrix corresponds to a single chromosome across all cells, preprocessed at a fixed resolution.\n",
    "\n",
    "\n",
    "### ðŸ”¹ 2. Model Configuration File (`config.json`)\n",
    "\n",
    "This JSON file stores model architecture settings and training hyperparameters.\n",
    "\n",
    "**Example content:**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"pretrain_epoch\": 150,\n",
    "  \"loss_ratio\": 0.02,\n",
    "  \"embed_dim\": 128,\n",
    "  \"num\": 0,\n",
    "  \"depth\": 4,\n",
    "  \"pretrain\": true,\n",
    "  \"hidden_dim\": 64,\n",
    "  \"vis\": true,\n",
    "  \"batch_size\": 32,\n",
    "  \"weight_decay\": 0.0,\n",
    "  \"epochs\": 180,\n",
    "  \"betas\": [0.9, 0.999],\n",
    "  \"patience\": 10,\n",
    "  \"learning rate\": 0.0005,\n",
    "  \"chr_single_loss\": true,\n",
    "  \"encoder_dim\": [],\n",
    "  \"weight\": 0.1,\n",
    "  \"patch_size\": [8, 16, 32, 64, 128],\n",
    "  \"chr_single_ratio\": 0.5,\n",
    "  \"mask_ratio\": 0.4,\n",
    "  \"atlr\": 0.0005,\n",
    "  \"otherlf\": \"MSE\",\n",
    "  \"enorm\": false\n",
    "}\n",
    "```\n",
    "\n",
    "This file is parsed at runtime to dynamically initialize the Hi-Cformer model and training loop.\n",
    "\n",
    "\n",
    "\n",
    "### ðŸ”¹ 3. Optional: Metadata File (`label_info.pickle`)\n",
    "\n",
    "This file stores metadata for each cell, such as **cell type** and **batch**, in the form of a dictionary of lists.  \n",
    "It is used **only during validation and visualization**, for tasks such as:\n",
    "\n",
    "- Coloring UMAP/t-SNE plots  \n",
    "- Evaluating embedding quality \n",
    "\n",
    "**Expected format:**\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"name\": [\"GSM7682144_BJ_cell_041\", \"GSM7682258_eHAP_029\", ...],\n",
    "  \"cell type\": [\"BJ\", \"eHAP\", ...],\n",
    "  \"batch\": [\"Batch1\", \"Batch2\", ...]\n",
    "}\n",
    "```\n",
    "\n",
    "Each list should be of the same length, with aligned entries.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ðŸ› ï¸ Workflow Overview\n",
    "\n",
    "1. **Data Loading & Model Initialization**  \n",
    "   Load per-chromosome `.npy` sparse matrices and parse model configuration. Dynamically build Hi-Cformer using parameters in the JSON file.\n",
    "\n",
    "3. **Training**  \n",
    "   Train on sparse Hi-C contact maps using appropriate loss functions.\n",
    "\n",
    "4. **Validation & Visualization**  \n",
    "   The modelâ€™s learned embeddings are visualized using UMAP, with cells colored by labels from label_info.pickle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading & model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed chr1\n",
      "Processed chr2\n",
      "Processed chr3\n",
      "Processed chr4\n",
      "Processed chr5\n",
      "Processed chr6\n",
      "Processed chr7\n",
      "Processed chr10\n",
      "Processed chr8\n",
      "Processed chr14\n",
      "Processed chr11\n",
      "Processed chr13\n",
      "Processed chr12\n",
      "Processed chr15\n",
      "Processed chr16\n",
      "Processed chr17\n",
      "Processed chr18\n",
      "Processed chr19\n",
      "Processed chr20\n",
      "Processed chr21\n",
      "Processed chr22\n",
      "Processed chrX\n",
      "hicformer(\n",
      "  (multi_encoder): ModuleList(\n",
      "    (0): block_encoder(\n",
      "      (proj): Conv2d(1, 128, kernel_size=(8, 8), stride=(8, 8))\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (1): block_encoder(\n",
      "      (proj): Conv2d(1, 128, kernel_size=(16, 16), stride=(16, 16))\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (2): block_encoder(\n",
      "      (proj): Conv2d(1, 128, kernel_size=(32, 32), stride=(32, 32))\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (3): block_encoder(\n",
      "      (proj): Conv2d(1, 128, kernel_size=(64, 64), stride=(64, 64))\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (4): block_encoder(\n",
      "      (proj): Conv2d(1, 128, kernel_size=(128, 128), stride=(128, 128))\n",
      "      (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pos_embed): Embedding(32, 128)\n",
      "  (size_embed): Embedding(5, 128)\n",
      "  (chr_embed): Embedding(22, 128)\n",
      "  (transformer_blocks): ModuleList(\n",
      "    (0-3): 4 x BlockWithCustomMask(\n",
      "      (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "        (q_norm): Identity()\n",
      "        (k_norm): Identity()\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (norm): Identity()\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "  (pred_hidden): Linear(in_features=2816, out_features=64, bias=True)\n",
      "  (latent_layer): Sequential()\n",
      "  (cell_decoder): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=229041, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (block_decoder): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=4096, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=16384, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (chr_decoder): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=31125, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from hicformer.model import hicformer\n",
    "from hicformer.utils import cal_expand_tensor\n",
    "\n",
    "# === Configuration ===\n",
    "# meta_data file and label key\n",
    "label_path = \"/home/wuxiaoqing/scHi-C_dataset/Wu2024_GSE240128/label_info.pickle\"\n",
    "label_name = \"cell type\"\n",
    "\n",
    "# sparse contact map folder\n",
    "raw_path = \"/home/wuxiaoqing/scHi-C_dataset/Wu2024_GSE240128/init_higashi/raw\"\n",
    "# chromosome list of input\n",
    "chr_list = ['chr1', 'chr2',  'chr3', 'chr4','chr5', 'chr6','chr7','chr10','chr8','chr14',\n",
    "             'chr11', 'chr13', 'chr12', 'chr15', 'chr16','chr17',  'chr18', 'chr19', 'chr20', 'chr21', 'chr22','chrX']\n",
    "\n",
    "# model configure file\n",
    "config_path = \"/home/wuxiaoqing/Hi-Cformer/demo/hicformer_params_0.json\"\n",
    "\n",
    "# === Load Labels ===\n",
    "with open(label_path, 'rb') as file:\n",
    "    datas = pickle.load(file)\n",
    "labels = datas[label_name]\n",
    "new_label = list(labels)\n",
    "cell_num = len(new_label)\n",
    "\n",
    "# === Load Model Config ===\n",
    "with open(config_path, 'r') as f:\n",
    "    args = json.load(f)\n",
    "\n",
    "def str2bool(x):\n",
    "    return x if isinstance(x, bool) else x.lower() == 'true'\n",
    "\n",
    "# Parse and fix parameters\n",
    "pretrain = str2bool(args.get(\"pretrain\", True))\n",
    "vis = str2bool(args.get(\"vis\", True))\n",
    "chr_single_loss = str2bool(args.get(\"chr_single_loss\", True))\n",
    "enorm = str2bool(args.get(\"enorm\", False))\n",
    "patch_size = args.get(\"patch_size\", [8, 16, 32, 64, 128])\n",
    "embed_dim = args.get(\"embed_dim\", 128)\n",
    "\n",
    "# === Load Data ===\n",
    "all_pics = []\n",
    "chr_cls = []\n",
    "max_height = 0\n",
    "\n",
    "for chrname in chr_list:\n",
    "    f = os.path.join(raw_path, chrname + '_sparse_adj.npy')\n",
    "    loaded_data = np.load(f, allow_pickle=True)\n",
    "\n",
    "    mats = [mat.toarray() for mat in loaded_data]\n",
    "    datas = np.array(mats)\n",
    "    max_height = max(max_height, datas.shape[1])\n",
    "\n",
    "    datas_flat = datas.reshape(datas.shape[0], -1)\n",
    "    onechr_pic = torch.stack([torch.tensor(pic, dtype=torch.float32).unsqueeze(0) for pic in mats])\n",
    "    all_pics.append(onechr_pic)\n",
    "\n",
    "    pca = PCA(n_components=embed_dim, random_state=3)\n",
    "    result = pca.fit_transform(datas_flat)\n",
    "    if enorm:\n",
    "        result = StandardScaler().fit_transform(result)\n",
    "    chr_cls.append(result)\n",
    "    print(f\"Processed {chrname}\")\n",
    "\n",
    "# Stack chromosome-level embeddings\n",
    "chr_tensor = torch.stack([torch.from_numpy(arr) for arr in chr_cls], dim=1)\n",
    "whole_size = sum(cal_expand_tensor(item) for item in all_pics)\n",
    "num_patches = max_height // min(patch_size)\n",
    "\n",
    "# === Construct Model ===\n",
    "\n",
    "allowed_model_keys = {\n",
    "    \"whole_size\", \"img_size\", \"hidden_dim\", \"patch_size\", \"encoder_dim\", \"chr_num\", \"in_chans\",\n",
    "    \"embed_dim\", \"depth\", \"num_heads\", \"mlp_ratio\", \"norm_layer\", \"chr_mutual_visibility\",\n",
    "    \"weight\", \"chr_single_loss\", \"num_patches\", \"otherlf\", \"enorm\", \"weight_mode\"\n",
    "}\n",
    "\n",
    "\n",
    "model_kwargs = {\n",
    "    key: val for key, val in {\n",
    "        \"whole_size\": whole_size,\n",
    "        \"img_size\": args.get(\"img_size\", max_height),\n",
    "        \"patch_size\": patch_size,\n",
    "        \"encoder_dim\": args.get(\"encoder_dim\", []),\n",
    "        \"hidden_dim\": args.get(\"hidden_dim\", 64),\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"depth\": args.get(\"depth\", 4),\n",
    "        \"chr_num\": len(chr_list),\n",
    "        \"in_chans\": 1,\n",
    "        \"num_heads\": 8,\n",
    "        \"mlp_ratio\": 4.0,\n",
    "        \"norm_layer\": partial(nn.LayerNorm, eps=1e-6),\n",
    "        \"chr_mutual_visibility\": vis,\n",
    "        \"weight\": args.get(\"weight\", 0.1),\n",
    "        \"chr_single_loss\": chr_single_loss,\n",
    "        \"num_patches\": num_patches,\n",
    "        \"otherlf\": args.get(\"otherlf\", 'MSE'),\n",
    "        \"enorm\": enorm,\n",
    "        \"weight_mode\": args.get(\"weight_mode\", 'mask'),\n",
    "    }.items() if key in allowed_model_keys\n",
    "}\n",
    "\n",
    "\n",
    "model = hicformer(**model_kwargs)\n",
    "device = torch.device(f\"cuda:{args.get('cuda', 1)}\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# === Calculate Average Contact for Each Cell ===\n",
    "cell_feats1 = torch.zeros((cell_num, 1), dtype=torch.float32)\n",
    "for i in range(cell_num):\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    for chrom_matrix in all_pics:\n",
    "        mat = chrom_matrix[i, :, :]\n",
    "        vals = mat[mat > 0]\n",
    "        total_sum += vals.sum().item()\n",
    "        total_count += vals.numel()\n",
    "    cell_feats1[i, 0] = total_sum / total_count if total_count > 0 else 0\n",
    "\n",
    "# === Create Dataset ===\n",
    "all_pics.append(chr_tensor)\n",
    "all_pics.append(cell_feats1)\n",
    "dataset = TensorDataset(*all_pics)\n",
    "data_loader_train = DataLoader(dataset, batch_size=args.get(\"batch_size\", 32), shuffle=True)\n",
    "data_loader_test = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Pretrain Phase1 Epoch 1/150, Chr Loss: 2160.8877\n",
      "Pretrain Phase1 Epoch 2/150, Chr Loss: 2057.5669\n",
      "Pretrain Phase1 Epoch 3/150, Chr Loss: 1936.0984\n",
      "Pretrain Phase1 Epoch 4/150, Chr Loss: 1746.6313\n",
      "Pretrain Phase1 Epoch 5/150, Chr Loss: 1551.8761\n",
      "Pretrain Phase1 Epoch 6/150, Chr Loss: 1308.8751\n",
      "Pretrain Phase1 Epoch 7/150, Chr Loss: 1077.3945\n",
      "Pretrain Phase1 Epoch 8/150, Chr Loss: 878.8890\n",
      "Pretrain Phase1 Epoch 9/150, Chr Loss: 725.2283\n",
      "Pretrain Phase1 Epoch 10/150, Chr Loss: 605.4678\n",
      "Pretrain Phase1 Epoch 11/150, Chr Loss: 526.6840\n",
      "Pretrain Phase1 Epoch 12/150, Chr Loss: 462.1163\n",
      "Pretrain Phase1 Epoch 13/150, Chr Loss: 421.4505\n",
      "Pretrain Phase1 Epoch 14/150, Chr Loss: 392.1474\n",
      "Pretrain Phase1 Epoch 15/150, Chr Loss: 359.3129\n",
      "Pretrain Phase1 Epoch 16/150, Chr Loss: 335.9930\n",
      "Pretrain Phase1 Epoch 17/150, Chr Loss: 318.7166\n",
      "Pretrain Phase1 Epoch 18/150, Chr Loss: 302.3165\n",
      "Pretrain Phase1 Epoch 19/150, Chr Loss: 292.8531\n",
      "Pretrain Phase1 Epoch 20/150, Chr Loss: 282.4542\n",
      "Pretrain Phase1 Epoch 21/150, Chr Loss: 273.2917\n",
      "Pretrain Phase1 Epoch 22/150, Chr Loss: 262.6567\n",
      "Pretrain Phase1 Epoch 23/150, Chr Loss: 253.7440\n",
      "Pretrain Phase1 Epoch 24/150, Chr Loss: 248.5786\n",
      "Pretrain Phase1 Epoch 25/150, Chr Loss: 243.1330\n",
      "Pretrain Phase1 Epoch 26/150, Chr Loss: 239.4422\n",
      "Pretrain Phase1 Epoch 27/150, Chr Loss: 228.4624\n",
      "Pretrain Phase1 Epoch 28/150, Chr Loss: 226.3355\n",
      "Pretrain Phase1 Epoch 29/150, Chr Loss: 220.2947\n",
      "Pretrain Phase1 Epoch 30/150, Chr Loss: 218.5938\n",
      "Pretrain Phase1 Epoch 31/150, Chr Loss: 210.3723\n",
      "Pretrain Phase1 Epoch 32/150, Chr Loss: 205.7180\n",
      "Pretrain Phase1 Epoch 33/150, Chr Loss: 205.8935\n",
      "Pretrain Phase1 Epoch 34/150, Chr Loss: 199.3226\n",
      "Pretrain Phase1 Epoch 35/150, Chr Loss: 194.4907\n",
      "Pretrain Phase1 Epoch 36/150, Chr Loss: 189.6881\n",
      "Pretrain Phase1 Epoch 37/150, Chr Loss: 183.8189\n",
      "Pretrain Phase1 Epoch 38/150, Chr Loss: 180.3871\n",
      "Pretrain Phase1 Epoch 39/150, Chr Loss: 180.9786\n",
      "Pretrain Phase1 Epoch 40/150, Chr Loss: 172.4294\n",
      "Pretrain Phase1 Epoch 41/150, Chr Loss: 166.7429\n",
      "Pretrain Phase1 Epoch 42/150, Chr Loss: 166.2495\n",
      "Pretrain Phase1 Epoch 43/150, Chr Loss: 161.8896\n",
      "Pretrain Phase1 Epoch 44/150, Chr Loss: 157.6374\n",
      "Pretrain Phase1 Epoch 45/150, Chr Loss: 156.7121\n",
      "Pretrain Phase1 Epoch 46/150, Chr Loss: 152.9718\n",
      "Pretrain Phase1 Epoch 47/150, Chr Loss: 149.7209\n",
      "Pretrain Phase1 Epoch 48/150, Chr Loss: 145.0421\n",
      "Pretrain Phase1 Epoch 49/150, Chr Loss: 145.3119\n",
      "Pretrain Phase1 Epoch 50/150, Chr Loss: 139.7883\n",
      "Pretrain Phase1 Epoch 51/150, Chr Loss: 136.4194\n",
      "Pretrain Phase1 Epoch 52/150, Chr Loss: 136.2614\n",
      "Pretrain Phase1 Epoch 53/150, Chr Loss: 131.3306\n",
      "Pretrain Phase1 Epoch 54/150, Chr Loss: 128.7999\n",
      "Pretrain Phase1 Epoch 55/150, Chr Loss: 125.9667\n",
      "Pretrain Phase1 Epoch 56/150, Chr Loss: 126.4947\n",
      "Pretrain Phase1 Epoch 57/150, Chr Loss: 123.4312\n",
      "Pretrain Phase1 Epoch 58/150, Chr Loss: 118.8734\n",
      "Pretrain Phase1 Epoch 59/150, Chr Loss: 116.5995\n",
      "Pretrain Phase1 Epoch 60/150, Chr Loss: 116.0298\n",
      "Pretrain Phase1 Epoch 61/150, Chr Loss: 116.9366\n",
      "Pretrain Phase1 Epoch 62/150, Chr Loss: 113.8801\n",
      "Pretrain Phase1 Epoch 63/150, Chr Loss: 112.5280\n",
      "Pretrain Phase1 Epoch 64/150, Chr Loss: 108.6184\n",
      "Pretrain Phase1 Epoch 65/150, Chr Loss: 107.1861\n",
      "Pretrain Phase1 Epoch 66/150, Chr Loss: 105.5062\n",
      "Pretrain Phase1 Epoch 67/150, Chr Loss: 105.0373\n",
      "Pretrain Phase1 Epoch 68/150, Chr Loss: 104.4125\n",
      "Pretrain Phase1 Epoch 69/150, Chr Loss: 102.7130\n",
      "Pretrain Phase1 Epoch 70/150, Chr Loss: 98.4001\n",
      "Pretrain Phase1 Epoch 71/150, Chr Loss: 97.8384\n",
      "Pretrain Phase1 Epoch 72/150, Chr Loss: 96.9480\n",
      "Pretrain Phase1 Epoch 73/150, Chr Loss: 96.0491\n",
      "Pretrain Phase1 Epoch 74/150, Chr Loss: 96.2297\n",
      "Pretrain Phase1 Epoch 75/150, Chr Loss: 95.3361\n",
      "Pretrain Phase1 Epoch 76/150, Chr Loss: 90.5087\n",
      "Pretrain Phase1 Epoch 77/150, Chr Loss: 95.8331\n",
      "Pretrain Phase1 Epoch 78/150, Chr Loss: 88.4462\n",
      "Pretrain Phase1 Epoch 79/150, Chr Loss: 88.2596\n",
      "Pretrain Phase1 Epoch 80/150, Chr Loss: 84.5242\n",
      "Pretrain Phase1 Epoch 81/150, Chr Loss: 82.6998\n",
      "Pretrain Phase1 Epoch 82/150, Chr Loss: 82.2225\n",
      "Pretrain Phase1 Epoch 83/150, Chr Loss: 81.5501\n",
      "Pretrain Phase1 Epoch 84/150, Chr Loss: 80.4108\n",
      "Pretrain Phase1 Epoch 85/150, Chr Loss: 78.5515\n",
      "Pretrain Phase1 Epoch 86/150, Chr Loss: 76.9738\n",
      "Pretrain Phase1 Epoch 87/150, Chr Loss: 76.7466\n",
      "Pretrain Phase1 Epoch 88/150, Chr Loss: 75.8428\n",
      "Pretrain Phase1 Epoch 89/150, Chr Loss: 75.2016\n",
      "Pretrain Phase1 Epoch 90/150, Chr Loss: 72.6760\n",
      "Pretrain Phase1 Epoch 91/150, Chr Loss: 73.0827\n",
      "Pretrain Phase1 Epoch 92/150, Chr Loss: 71.1854\n",
      "Pretrain Phase1 Epoch 93/150, Chr Loss: 69.9453\n",
      "Pretrain Phase1 Epoch 94/150, Chr Loss: 68.5183\n",
      "Pretrain Phase1 Epoch 95/150, Chr Loss: 68.2478\n",
      "Pretrain Phase1 Epoch 96/150, Chr Loss: 68.1621\n",
      "Pretrain Phase1 Epoch 97/150, Chr Loss: 66.9114\n",
      "Pretrain Phase1 Epoch 98/150, Chr Loss: 68.5220\n",
      "Pretrain Phase1 Epoch 99/150, Chr Loss: 65.3095\n",
      "Pretrain Phase1 Epoch 100/150, Chr Loss: 66.0527\n",
      "Pretrain Phase1 Epoch 101/150, Chr Loss: 66.0370\n",
      "Pretrain Phase1 Epoch 102/150, Chr Loss: 66.0187\n",
      "Pretrain Phase1 Epoch 103/150, Chr Loss: 64.0718\n",
      "Pretrain Phase1 Epoch 104/150, Chr Loss: 61.2728\n",
      "Pretrain Phase1 Epoch 105/150, Chr Loss: 61.6931\n",
      "Pretrain Phase1 Epoch 106/150, Chr Loss: 62.0150\n",
      "Pretrain Phase1 Epoch 107/150, Chr Loss: 60.0356\n",
      "Pretrain Phase1 Epoch 108/150, Chr Loss: 59.6525\n",
      "Pretrain Phase1 Epoch 109/150, Chr Loss: 59.0718\n",
      "Pretrain Phase1 Epoch 110/150, Chr Loss: 58.3866\n",
      "Pretrain Phase1 Epoch 111/150, Chr Loss: 58.1099\n",
      "Pretrain Phase1 Epoch 112/150, Chr Loss: 57.0893\n",
      "Pretrain Phase1 Epoch 113/150, Chr Loss: 57.8845\n",
      "Pretrain Phase1 Epoch 114/150, Chr Loss: 55.7729\n",
      "Pretrain Phase1 Epoch 115/150, Chr Loss: 55.5407\n",
      "Pretrain Phase1 Epoch 116/150, Chr Loss: 54.7255\n",
      "Pretrain Phase1 Epoch 117/150, Chr Loss: 54.6489\n",
      "Pretrain Phase1 Epoch 118/150, Chr Loss: 55.1226\n",
      "Pretrain Phase1 Epoch 119/150, Chr Loss: 54.2980\n",
      "Pretrain Phase1 Epoch 120/150, Chr Loss: 54.1918\n",
      "Pretrain Phase1 Epoch 121/150, Chr Loss: 59.1706\n",
      "Pretrain Phase1 Epoch 122/150, Chr Loss: 52.2203\n",
      "Pretrain Phase1 Epoch 123/150, Chr Loss: 52.3839\n",
      "Pretrain Phase1 Epoch 124/150, Chr Loss: 50.9592\n",
      "Pretrain Phase1 Epoch 125/150, Chr Loss: 51.2880\n",
      "Pretrain Phase1 Epoch 126/150, Chr Loss: 50.9714\n",
      "Pretrain Phase1 Epoch 127/150, Chr Loss: 50.1683\n",
      "Pretrain Phase1 Epoch 128/150, Chr Loss: 49.7414\n",
      "Pretrain Phase1 Epoch 129/150, Chr Loss: 49.5989\n",
      "Pretrain Phase1 Epoch 130/150, Chr Loss: 49.3249\n",
      "Pretrain Phase1 Epoch 131/150, Chr Loss: 48.5301\n",
      "Pretrain Phase1 Epoch 132/150, Chr Loss: 48.5006\n",
      "Pretrain Phase1 Epoch 133/150, Chr Loss: 48.5799\n",
      "Pretrain Phase1 Epoch 134/150, Chr Loss: 48.7220\n",
      "Pretrain Phase1 Epoch 135/150, Chr Loss: 47.8715\n",
      "Pretrain Phase1 Epoch 136/150, Chr Loss: 47.3905\n",
      "Pretrain Phase1 Epoch 137/150, Chr Loss: 47.4677\n",
      "Pretrain Phase1 Epoch 138/150, Chr Loss: 46.6967\n",
      "Pretrain Phase1 Epoch 139/150, Chr Loss: 46.4926\n",
      "Pretrain Phase1 Epoch 140/150, Chr Loss: 45.9265\n",
      "Pretrain Phase1 Epoch 141/150, Chr Loss: 46.2412\n",
      "Pretrain Phase1 Epoch 142/150, Chr Loss: 45.9193\n",
      "Pretrain Phase1 Epoch 143/150, Chr Loss: 46.4391\n",
      "Pretrain Phase1 Epoch 144/150, Chr Loss: 45.6533\n",
      "Pretrain Phase1 Epoch 145/150, Chr Loss: 45.4156\n",
      "Pretrain Phase1 Epoch 146/150, Chr Loss: 45.3518\n",
      "Pretrain Phase1 Epoch 147/150, Chr Loss: 45.1325\n",
      "Pretrain Phase1 Epoch 148/150, Chr Loss: 45.2982\n",
      "Pretrain Phase1 Epoch 149/150, Chr Loss: 44.6327\n",
      "Pretrain Phase1 Epoch 150/150, Chr Loss: 45.0048\n",
      "Pretrain Phase2 Epoch 1/150, Patch Loss: 25369.7508\n",
      "Pretrain Phase2 Epoch 2/150, Patch Loss: 23956.5958\n",
      "Pretrain Phase2 Epoch 3/150, Patch Loss: 22482.1915\n",
      "Pretrain Phase2 Epoch 4/150, Patch Loss: 21220.6303\n",
      "Pretrain Phase2 Epoch 5/150, Patch Loss: 19916.1025\n",
      "Pretrain Phase2 Epoch 6/150, Patch Loss: 18742.7034\n",
      "Pretrain Phase2 Epoch 7/150, Patch Loss: 17688.2539\n",
      "Pretrain Phase2 Epoch 8/150, Patch Loss: 16749.5680\n",
      "Pretrain Phase2 Epoch 9/150, Patch Loss: 15877.3209\n",
      "Pretrain Phase2 Epoch 10/150, Patch Loss: 15082.0088\n",
      "Pretrain Phase2 Epoch 11/150, Patch Loss: 14475.3551\n",
      "Pretrain Phase2 Epoch 12/150, Patch Loss: 13903.8048\n",
      "Pretrain Phase2 Epoch 13/150, Patch Loss: 13332.9234\n",
      "Pretrain Phase2 Epoch 14/150, Patch Loss: 13013.1090\n",
      "Pretrain Phase2 Epoch 15/150, Patch Loss: 12607.2414\n",
      "Pretrain Phase2 Epoch 16/150, Patch Loss: 12410.5179\n",
      "Pretrain Phase2 Epoch 17/150, Patch Loss: 12089.9027\n",
      "Pretrain Phase2 Epoch 18/150, Patch Loss: 11954.9636\n",
      "Pretrain Phase2 Epoch 19/150, Patch Loss: 11909.7269\n",
      "Pretrain Phase2 Epoch 20/150, Patch Loss: 11613.1546\n",
      "Pretrain Phase2 Epoch 21/150, Patch Loss: 11629.8568\n",
      "Pretrain Phase2 Epoch 22/150, Patch Loss: 11472.8772\n",
      "Pretrain Phase2 Epoch 23/150, Patch Loss: 11314.7851\n",
      "Pretrain Phase2 Epoch 24/150, Patch Loss: 11302.4716\n",
      "Pretrain Phase2 Epoch 25/150, Patch Loss: 11126.0947\n",
      "Pretrain Phase2 Epoch 26/150, Patch Loss: 10961.3940\n",
      "Pretrain Phase2 Epoch 27/150, Patch Loss: 10892.4667\n",
      "Pretrain Phase2 Epoch 28/150, Patch Loss: 10762.3307\n",
      "Pretrain Phase2 Epoch 29/150, Patch Loss: 10711.3136\n",
      "Pretrain Phase2 Epoch 30/150, Patch Loss: 10558.2828\n",
      "Pretrain Phase2 Epoch 31/150, Patch Loss: 10456.8904\n",
      "Pretrain Phase2 Epoch 32/150, Patch Loss: 10495.7681\n",
      "Pretrain Phase2 Epoch 33/150, Patch Loss: 10339.1618\n",
      "Pretrain Phase2 Epoch 34/150, Patch Loss: 10410.0536\n",
      "Pretrain Phase2 Epoch 35/150, Patch Loss: 10291.2435\n",
      "Pretrain Phase2 Epoch 36/150, Patch Loss: 10258.3440\n",
      "Pretrain Phase2 Epoch 37/150, Patch Loss: 10176.2398\n",
      "Pretrain Phase2 Epoch 38/150, Patch Loss: 10157.3101\n",
      "Pretrain Phase2 Epoch 39/150, Patch Loss: 9924.7547\n",
      "Pretrain Phase2 Epoch 40/150, Patch Loss: 10033.3451\n",
      "Pretrain Phase2 Epoch 41/150, Patch Loss: 9939.0541\n",
      "Pretrain Phase2 Epoch 42/150, Patch Loss: 9819.8086\n",
      "Pretrain Phase2 Epoch 43/150, Patch Loss: 9759.0734\n",
      "Pretrain Phase2 Epoch 44/150, Patch Loss: 9876.2023\n",
      "Pretrain Phase2 Epoch 45/150, Patch Loss: 9759.4530\n",
      "Pretrain Phase2 Epoch 46/150, Patch Loss: 9615.8263\n",
      "Pretrain Phase2 Epoch 47/150, Patch Loss: 9653.8909\n",
      "Pretrain Phase2 Epoch 48/150, Patch Loss: 9646.5354\n",
      "Pretrain Phase2 Epoch 49/150, Patch Loss: 9477.7344\n",
      "Pretrain Phase2 Epoch 50/150, Patch Loss: 9591.6800\n",
      "Pretrain Phase2 Epoch 51/150, Patch Loss: 9503.1003\n",
      "Pretrain Phase2 Epoch 52/150, Patch Loss: 9359.5893\n",
      "Pretrain Phase2 Epoch 53/150, Patch Loss: 9394.2959\n",
      "Pretrain Phase2 Epoch 54/150, Patch Loss: 9341.5209\n",
      "Pretrain Phase2 Epoch 55/150, Patch Loss: 9381.5841\n",
      "Pretrain Phase2 Epoch 56/150, Patch Loss: 9343.2399\n",
      "Pretrain Phase2 Epoch 57/150, Patch Loss: 9459.4054\n",
      "Pretrain Phase2 Epoch 58/150, Patch Loss: 9308.2418\n",
      "Pretrain Phase2 Epoch 59/150, Patch Loss: 9397.0804\n",
      "Pretrain Phase2 Epoch 60/150, Patch Loss: 9460.1111\n",
      "Pretrain Phase2 Epoch 61/150, Patch Loss: 9360.2379\n",
      "Pretrain Phase2 Epoch 62/150, Patch Loss: 9215.5194\n",
      "Pretrain Phase2 Epoch 63/150, Patch Loss: 9039.6958\n",
      "Pretrain Phase2 Epoch 64/150, Patch Loss: 9456.1196\n",
      "Pretrain Phase2 Epoch 65/150, Patch Loss: 9265.6628\n",
      "Pretrain Phase2 Epoch 66/150, Patch Loss: 9171.9113\n",
      "Pretrain Phase2 Epoch 67/150, Patch Loss: 8970.1825\n",
      "Pretrain Phase2 Epoch 68/150, Patch Loss: 9100.5194\n",
      "Pretrain Phase2 Epoch 69/150, Patch Loss: 9182.3655\n",
      "Pretrain Phase2 Epoch 70/150, Patch Loss: 9041.4286\n",
      "Pretrain Phase2 Epoch 71/150, Patch Loss: 9073.3455\n",
      "Pretrain Phase2 Epoch 72/150, Patch Loss: 9096.3283\n",
      "Pretrain Phase2 Epoch 73/150, Patch Loss: 9086.5975\n",
      "Pretrain Phase2 Epoch 74/150, Patch Loss: 9114.6448\n",
      "Pretrain Phase2 Epoch 75/150, Patch Loss: 9090.2992\n",
      "Pretrain Phase2 Epoch 76/150, Patch Loss: 8945.2712\n",
      "Pretrain Phase2 Epoch 77/150, Patch Loss: 8951.0241\n",
      "Pretrain Phase2 Epoch 78/150, Patch Loss: 9018.7391\n",
      "Pretrain Phase2 Epoch 79/150, Patch Loss: 9240.8975\n",
      "Pretrain Phase2 Epoch 80/150, Patch Loss: 8834.8546\n",
      "Pretrain Phase2 Epoch 81/150, Patch Loss: 9021.1511\n",
      "Pretrain Phase2 Epoch 82/150, Patch Loss: 8953.5903\n",
      "Pretrain Phase2 Epoch 83/150, Patch Loss: 8946.2565\n",
      "Pretrain Phase2 Epoch 84/150, Patch Loss: 8853.1808\n",
      "Pretrain Phase2 Epoch 85/150, Patch Loss: 8820.1525\n",
      "Pretrain Phase2 Epoch 86/150, Patch Loss: 8932.5766\n",
      "Pretrain Phase2 Epoch 87/150, Patch Loss: 8904.0385\n",
      "Pretrain Phase2 Epoch 88/150, Patch Loss: 8759.6666\n",
      "Pretrain Phase2 Epoch 89/150, Patch Loss: 8998.3896\n",
      "Pretrain Phase2 Epoch 90/150, Patch Loss: 9069.2063\n",
      "Pretrain Phase2 Epoch 91/150, Patch Loss: 8961.4653\n",
      "Pretrain Phase2 Epoch 92/150, Patch Loss: 8716.7990\n",
      "Pretrain Phase2 Epoch 93/150, Patch Loss: 8695.6852\n",
      "Pretrain Phase2 Epoch 94/150, Patch Loss: 8681.2358\n",
      "Pretrain Phase2 Epoch 95/150, Patch Loss: 8648.9486\n",
      "Pretrain Phase2 Epoch 96/150, Patch Loss: 8805.2417\n",
      "Pretrain Phase2 Epoch 97/150, Patch Loss: 8714.1710\n",
      "Pretrain Phase2 Epoch 98/150, Patch Loss: 8820.5308\n",
      "Pretrain Phase2 Epoch 99/150, Patch Loss: 8932.5951\n",
      "Pretrain Phase2 Epoch 100/150, Patch Loss: 8730.4258\n",
      "Pretrain Phase2 Epoch 101/150, Patch Loss: 8921.2317\n",
      "Pretrain Phase2 Epoch 102/150, Patch Loss: 8741.1210\n",
      "Pretrain Phase2 Epoch 103/150, Patch Loss: 8561.1972\n",
      "Pretrain Phase2 Epoch 104/150, Patch Loss: 8812.9303\n",
      "Pretrain Phase2 Epoch 105/150, Patch Loss: 8548.2366\n",
      "Pretrain Phase2 Epoch 106/150, Patch Loss: 8572.8821\n",
      "Pretrain Phase2 Epoch 107/150, Patch Loss: 8522.4359\n",
      "Pretrain Phase2 Epoch 108/150, Patch Loss: 8688.2576\n",
      "Pretrain Phase2 Epoch 109/150, Patch Loss: 8622.1924\n",
      "Pretrain Phase2 Epoch 110/150, Patch Loss: 8661.9577\n",
      "Pretrain Phase2 Epoch 111/150, Patch Loss: 8940.7025\n",
      "Pretrain Phase2 Epoch 112/150, Patch Loss: 8904.5637\n",
      "Pretrain Phase2 Epoch 113/150, Patch Loss: 8499.8018\n",
      "Pretrain Phase2 Epoch 114/150, Patch Loss: 8855.1987\n",
      "Pretrain Phase2 Epoch 115/150, Patch Loss: 8632.2000\n",
      "Pretrain Phase2 Epoch 116/150, Patch Loss: 8705.9871\n",
      "Pretrain Phase2 Epoch 117/150, Patch Loss: 8676.6940\n",
      "Pretrain Phase2 Epoch 118/150, Patch Loss: 8587.6140\n",
      "Pretrain Phase2 Epoch 119/150, Patch Loss: 8458.2365\n",
      "Pretrain Phase2 Epoch 120/150, Patch Loss: 8454.6716\n",
      "Pretrain Phase2 Epoch 121/150, Patch Loss: 8446.5369\n",
      "Pretrain Phase2 Epoch 122/150, Patch Loss: 8454.4191\n",
      "Pretrain Phase2 Epoch 123/150, Patch Loss: 8429.6269\n",
      "Pretrain Phase2 Epoch 124/150, Patch Loss: 8651.7307\n",
      "Pretrain Phase2 Epoch 125/150, Patch Loss: 8433.7069\n",
      "Pretrain Phase2 Epoch 126/150, Patch Loss: 8393.7025\n",
      "Pretrain Phase2 Epoch 127/150, Patch Loss: 8414.1842\n",
      "Pretrain Phase2 Epoch 128/150, Patch Loss: 8471.0366\n",
      "Pretrain Phase2 Epoch 129/150, Patch Loss: 8396.0769\n",
      "Pretrain Phase2 Epoch 130/150, Patch Loss: 8375.1672\n",
      "Pretrain Phase2 Epoch 131/150, Patch Loss: 8363.2201\n",
      "Pretrain Phase2 Epoch 132/150, Patch Loss: 8490.9901\n",
      "Pretrain Phase2 Epoch 133/150, Patch Loss: 8456.7732\n",
      "Pretrain Phase2 Epoch 134/150, Patch Loss: 8377.8506\n",
      "Pretrain Phase2 Epoch 135/150, Patch Loss: 8390.5416\n",
      "Pretrain Phase2 Epoch 136/150, Patch Loss: 8543.7022\n",
      "Pretrain Phase2 Epoch 137/150, Patch Loss: 8436.4285\n",
      "Pretrain Phase2 Epoch 138/150, Patch Loss: 8352.5207\n",
      "Pretrain Phase2 Epoch 139/150, Patch Loss: 8491.7149\n",
      "Pretrain Phase2 Epoch 140/150, Patch Loss: 8429.0306\n",
      "Pretrain Phase2 Epoch 141/150, Patch Loss: 8393.8335\n",
      "Pretrain Phase2 Epoch 142/150, Patch Loss: 8485.7441\n",
      "Pretrain Phase2 Epoch 143/150, Patch Loss: 8419.1520\n",
      "Pretrain Phase2 Epoch 144/150, Patch Loss: 8381.5284\n",
      "Pretrain Phase2 Epoch 145/150, Patch Loss: 8429.4555\n",
      "Pretrain Phase2 Epoch 146/150, Patch Loss: 8497.4129\n",
      "Pretrain Phase2 Epoch 147/150, Patch Loss: 8341.7724\n",
      "Pretrain Phase2 Epoch 148/150, Patch Loss: 8246.6003\n",
      "Pretrain Phase2 Epoch 149/150, Patch Loss: 8352.2239\n",
      "Pretrain Phase2 Epoch 150/150, Patch Loss: 8431.2424\n",
      "Start training for 120 epochs\n",
      "Epoch 1/120, Total Loss: 450.0278, Patch Loss: 12024.8841, Chr Loss: 252.8693, Chr Single Loss: 18810.0739\n",
      "Epoch 2/120, Total Loss: 285.5454, Patch Loss: 11738.4916, Chr Loss: 95.9434, Chr Single Loss: 17909.6948\n",
      "Epoch 3/120, Total Loss: 257.5784, Patch Loss: 11060.7180, Chr Loss: 82.4223, Chr Single Loss: 16516.6344\n",
      "Epoch 4/120, Total Loss: 224.4139, Patch Loss: 10235.8836, Chr Loss: 71.3277, Chr Single Loss: 14377.7983\n",
      "Epoch 5/120, Total Loss: 193.7074, Patch Loss: 9826.2136, Chr Loss: 64.8888, Chr Single Loss: 11982.5360\n",
      "Epoch 6/120, Total Loss: 185.8969, Patch Loss: 9659.9596, Chr Loss: 69.9271, Chr Single Loss: 10718.5481\n",
      "Epoch 7/120, Total Loss: 175.3272, Patch Loss: 9560.9884, Chr Loss: 66.5866, Chr Single Loss: 10001.1480\n",
      "Epoch 8/120, Total Loss: 170.7916, Patch Loss: 9424.0880, Chr Loss: 68.9913, Chr Single Loss: 9322.7726\n",
      "Epoch 9/120, Total Loss: 159.6148, Patch Loss: 9447.8388, Chr Loss: 63.0929, Chr Single Loss: 8785.5249\n",
      "Epoch 10/120, Total Loss: 157.1614, Patch Loss: 9393.8786, Chr Loss: 65.9802, Chr Single Loss: 8259.5025\n",
      "Epoch 11/120, Total Loss: 150.2685, Patch Loss: 9359.1823, Chr Loss: 61.5562, Chr Single Loss: 8010.9703\n",
      "Epoch 12/120, Total Loss: 147.1095, Patch Loss: 9434.0140, Chr Loss: 60.3285, Chr Single Loss: 7808.8092\n",
      "Epoch 13/120, Total Loss: 154.4502, Patch Loss: 9453.8098, Chr Loss: 68.2524, Chr Single Loss: 7757.1669\n",
      "Epoch 14/120, Total Loss: 145.5401, Patch Loss: 9320.4170, Chr Loss: 60.7310, Chr Single Loss: 7623.2432\n",
      "Epoch 15/120, Total Loss: 143.1945, Patch Loss: 9263.1577, Chr Loss: 59.5230, Chr Single Loss: 7513.7587\n",
      "Epoch 16/120, Total Loss: 142.9426, Patch Loss: 9234.9515, Chr Loss: 60.0185, Chr Single Loss: 7442.3149\n",
      "Epoch 17/120, Total Loss: 142.9438, Patch Loss: 9212.0590, Chr Loss: 61.3459, Chr Single Loss: 7313.3231\n",
      "Epoch 18/120, Total Loss: 139.1066, Patch Loss: 9065.9485, Chr Loss: 58.7034, Chr Single Loss: 7205.4427\n",
      "Epoch 19/120, Total Loss: 134.6300, Patch Loss: 9010.4279, Chr Loss: 55.7283, Chr Single Loss: 7057.4324\n",
      "Epoch 20/120, Total Loss: 134.4505, Patch Loss: 9099.6475, Chr Loss: 55.5609, Chr Single Loss: 7047.1009\n",
      "Epoch 21/120, Total Loss: 130.9499, Patch Loss: 9052.8570, Chr Loss: 53.2954, Chr Single Loss: 6925.6633\n",
      "Epoch 22/120, Total Loss: 131.3169, Patch Loss: 9062.4724, Chr Loss: 54.3537, Chr Single Loss: 6856.6643\n",
      "Epoch 23/120, Total Loss: 130.2469, Patch Loss: 8955.5374, Chr Loss: 54.4198, Chr Single Loss: 6753.7221\n",
      "Epoch 24/120, Total Loss: 133.8672, Patch Loss: 9050.2208, Chr Loss: 58.4642, Chr Single Loss: 6706.2386\n",
      "Epoch 25/120, Total Loss: 131.0372, Patch Loss: 8975.0117, Chr Loss: 55.4576, Chr Single Loss: 6728.1253\n",
      "Epoch 26/120, Total Loss: 130.6024, Patch Loss: 8919.1858, Chr Loss: 55.8623, Chr Single Loss: 6650.1341\n",
      "Epoch 27/120, Total Loss: 130.7084, Patch Loss: 9015.5309, Chr Loss: 55.0416, Chr Single Loss: 6732.3501\n",
      "Epoch 28/120, Total Loss: 131.4976, Patch Loss: 8947.5313, Chr Loss: 56.2346, Chr Single Loss: 6700.0538\n",
      "Epoch 29/120, Total Loss: 130.3320, Patch Loss: 8954.4571, Chr Loss: 56.0803, Chr Single Loss: 6597.9532\n",
      "Epoch 30/120, Total Loss: 128.1635, Patch Loss: 9022.0690, Chr Loss: 53.9973, Chr Single Loss: 6580.3391\n",
      "Epoch 31/120, Total Loss: 126.2859, Patch Loss: 8912.7838, Chr Loss: 53.6762, Chr Single Loss: 6435.1121\n",
      "Epoch 32/120, Total Loss: 128.1541, Patch Loss: 8899.5874, Chr Loss: 55.1250, Chr Single Loss: 6480.0090\n",
      "Epoch 33/120, Total Loss: 126.2420, Patch Loss: 8974.4803, Chr Loss: 53.3642, Chr Single Loss: 6455.4308\n",
      "Epoch 34/120, Total Loss: 126.6574, Patch Loss: 8853.6028, Chr Loss: 54.7357, Chr Single Loss: 6373.3364\n",
      "Epoch 35/120, Total Loss: 125.1117, Patch Loss: 9041.8235, Chr Loss: 53.0175, Chr Single Loss: 6369.8701\n",
      "Epoch 36/120, Total Loss: 125.4803, Patch Loss: 8983.0920, Chr Loss: 53.7624, Chr Single Loss: 6338.9006\n",
      "Epoch 37/120, Total Loss: 121.2364, Patch Loss: 8940.3619, Chr Loss: 50.5464, Chr Single Loss: 6236.7467\n",
      "Epoch 38/120, Total Loss: 122.3766, Patch Loss: 8831.6940, Chr Loss: 51.9134, Chr Single Loss: 6226.4333\n",
      "Epoch 39/120, Total Loss: 121.4591, Patch Loss: 8885.2577, Chr Loss: 50.9704, Chr Single Loss: 6222.5851\n",
      "Epoch 40/120, Total Loss: 120.0661, Patch Loss: 8841.5121, Chr Loss: 50.2064, Chr Single Loss: 6163.1591\n",
      "Epoch 41/120, Total Loss: 120.8032, Patch Loss: 8902.8550, Chr Loss: 50.5278, Chr Single Loss: 6198.9843\n",
      "Epoch 42/120, Total Loss: 120.0197, Patch Loss: 8799.3060, Chr Loss: 49.7992, Chr Single Loss: 6203.0612\n",
      "Epoch 43/120, Total Loss: 120.4456, Patch Loss: 8911.9766, Chr Loss: 50.2753, Chr Single Loss: 6187.2751\n",
      "Epoch 44/120, Total Loss: 119.2335, Patch Loss: 8833.8487, Chr Loss: 50.4488, Chr Single Loss: 6056.5830\n",
      "Epoch 45/120, Total Loss: 116.9136, Patch Loss: 8792.4884, Chr Loss: 48.9600, Chr Single Loss: 5975.8857\n",
      "Epoch 46/120, Total Loss: 116.8872, Patch Loss: 8783.5115, Chr Loss: 47.8760, Chr Single Loss: 6081.4712\n",
      "Epoch 47/120, Total Loss: 116.1399, Patch Loss: 8781.7551, Chr Loss: 48.3237, Chr Single Loss: 5962.5156\n",
      "Epoch 48/120, Total Loss: 118.1875, Patch Loss: 8989.5755, Chr Loss: 50.2085, Chr Single Loss: 5960.0850\n",
      "Epoch 49/120, Total Loss: 115.3239, Patch Loss: 8783.6395, Chr Loss: 47.5714, Chr Single Loss: 5955.1186\n",
      "Epoch 50/120, Total Loss: 115.4882, Patch Loss: 8812.0694, Chr Loss: 48.0076, Chr Single Loss: 5925.5405\n",
      "Epoch 51/120, Total Loss: 114.8450, Patch Loss: 8726.4019, Chr Loss: 48.3384, Chr Single Loss: 5836.9822\n",
      "Epoch 52/120, Total Loss: 115.6346, Patch Loss: 8727.8635, Chr Loss: 49.7240, Chr Single Loss: 5778.7053\n",
      "Epoch 53/120, Total Loss: 116.0640, Patch Loss: 8830.4410, Chr Loss: 49.7722, Chr Single Loss: 5806.6440\n",
      "Epoch 54/120, Total Loss: 114.1301, Patch Loss: 8701.3420, Chr Loss: 47.9452, Chr Single Loss: 5806.8603\n",
      "Epoch 55/120, Total Loss: 114.7256, Patch Loss: 8825.6251, Chr Loss: 48.2475, Chr Single Loss: 5824.0975\n",
      "Epoch 56/120, Total Loss: 114.4749, Patch Loss: 8776.0831, Chr Loss: 48.6179, Chr Single Loss: 5767.2878\n",
      "Epoch 57/120, Total Loss: 113.3898, Patch Loss: 8717.7058, Chr Loss: 48.2667, Chr Single Loss: 5699.2874\n",
      "Epoch 58/120, Total Loss: 115.0225, Patch Loss: 8705.1528, Chr Loss: 49.9634, Chr Single Loss: 5695.9982\n",
      "Epoch 59/120, Total Loss: 113.6697, Patch Loss: 8963.1150, Chr Loss: 47.0815, Chr Single Loss: 5820.0671\n",
      "Epoch 60/120, Total Loss: 113.2476, Patch Loss: 8908.0775, Chr Loss: 47.5179, Chr Single Loss: 5740.1273\n",
      "Epoch 61/120, Total Loss: 113.5440, Patch Loss: 8739.4674, Chr Loss: 49.0315, Chr Single Loss: 5636.8201\n",
      "Epoch 62/120, Total Loss: 110.9880, Patch Loss: 8692.0927, Chr Loss: 46.6209, Chr Single Loss: 5624.3615\n",
      "Epoch 63/120, Total Loss: 111.0174, Patch Loss: 9046.1989, Chr Loss: 47.0827, Chr Single Loss: 5546.1392\n",
      "Epoch 64/120, Total Loss: 111.8689, Patch Loss: 8719.2992, Chr Loss: 47.0660, Chr Single Loss: 5665.7451\n",
      "Epoch 65/120, Total Loss: 111.6287, Patch Loss: 8762.8270, Chr Loss: 47.1606, Chr Single Loss: 5627.9852\n",
      "Epoch 66/120, Total Loss: 110.9564, Patch Loss: 8636.9009, Chr Loss: 47.4312, Chr Single Loss: 5546.5005\n",
      "Epoch 67/120, Total Loss: 111.4554, Patch Loss: 8719.2174, Chr Loss: 48.0442, Chr Single Loss: 5527.5242\n",
      "Epoch 68/120, Total Loss: 110.2095, Patch Loss: 8572.5256, Chr Loss: 46.9754, Chr Single Loss: 5523.3073\n",
      "Epoch 69/120, Total Loss: 108.9559, Patch Loss: 8692.3033, Chr Loss: 44.8246, Chr Single Loss: 5598.7567\n",
      "Epoch 70/120, Total Loss: 109.4671, Patch Loss: 8670.6657, Chr Loss: 46.4241, Chr Single Loss: 5493.7423\n",
      "Epoch 71/120, Total Loss: 110.6296, Patch Loss: 8611.7464, Chr Loss: 47.1313, Chr Single Loss: 5545.9945\n",
      "Epoch 72/120, Total Loss: 110.0461, Patch Loss: 9006.4840, Chr Loss: 46.2361, Chr Single Loss: 5536.7033\n",
      "Epoch 73/120, Total Loss: 108.9005, Patch Loss: 8730.6277, Chr Loss: 46.2100, Chr Single Loss: 5452.2207\n",
      "Epoch 74/120, Total Loss: 107.8997, Patch Loss: 8594.8658, Chr Loss: 45.7532, Chr Single Loss: 5410.8568\n",
      "Epoch 75/120, Total Loss: 108.9251, Patch Loss: 8618.0924, Chr Loss: 46.6294, Chr Single Loss: 5424.4341\n",
      "Epoch 76/120, Total Loss: 109.4089, Patch Loss: 8662.5437, Chr Loss: 47.5907, Chr Single Loss: 5373.2374\n",
      "Epoch 77/120, Total Loss: 114.5088, Patch Loss: 9552.1042, Chr Loss: 50.1011, Chr Single Loss: 5546.1704\n",
      "Epoch 78/120, Total Loss: 108.4686, Patch Loss: 8731.3975, Chr Loss: 46.6704, Chr Single Loss: 5363.3328\n",
      "Epoch 79/120, Total Loss: 106.6712, Patch Loss: 8621.2544, Chr Loss: 45.2702, Chr Single Loss: 5333.0626\n",
      "Epoch 80/120, Total Loss: 106.0929, Patch Loss: 8631.2711, Chr Loss: 44.4110, Chr Single Loss: 5359.2270\n",
      "Epoch 81/120, Total Loss: 105.2634, Patch Loss: 8672.5809, Chr Loss: 43.8407, Chr Single Loss: 5328.5219\n",
      "Epoch 82/120, Total Loss: 105.3015, Patch Loss: 8673.0069, Chr Loss: 43.8788, Chr Single Loss: 5328.5158\n",
      "Epoch 83/120, Total Loss: 105.9852, Patch Loss: 8699.9277, Chr Loss: 44.5068, Chr Single Loss: 5332.0956\n",
      "Epoch 84/120, Total Loss: 106.2373, Patch Loss: 8818.3411, Chr Loss: 44.0666, Chr Single Loss: 5389.0552\n",
      "Epoch 85/120, Total Loss: 107.8096, Patch Loss: 8950.2806, Chr Loss: 44.9639, Chr Single Loss: 5444.4019\n",
      "Epoch 86/120, Total Loss: 106.1911, Patch Loss: 8601.6208, Chr Loss: 45.2401, Chr Single Loss: 5289.9474\n",
      "Epoch 87/120, Total Loss: 106.7136, Patch Loss: 8572.2196, Chr Loss: 45.1321, Chr Single Loss: 5355.8779\n",
      "Epoch 88/120, Total Loss: 109.2791, Patch Loss: 8502.1585, Chr Loss: 49.0542, Chr Single Loss: 5231.4194\n",
      "Epoch 89/120, Total Loss: 109.5928, Patch Loss: 8862.8918, Chr Loss: 48.3823, Chr Single Loss: 5293.2198\n",
      "Epoch 90/120, Total Loss: 107.0516, Patch Loss: 8840.3427, Chr Loss: 45.8244, Chr Single Loss: 5294.3416\n",
      "Epoch 91/120, Total Loss: 104.7541, Patch Loss: 8745.8553, Chr Loss: 43.9554, Chr Single Loss: 5258.8537\n",
      "Epoch 92/120, Total Loss: 102.6175, Patch Loss: 8707.7308, Chr Loss: 42.7883, Chr Single Loss: 5164.3394\n",
      "Epoch 93/120, Total Loss: 103.4998, Patch Loss: 8771.0566, Chr Loss: 43.1754, Chr Single Loss: 5208.0004\n",
      "Epoch 94/120, Total Loss: 104.5358, Patch Loss: 8579.1236, Chr Loss: 44.5747, Chr Single Loss: 5192.3792\n",
      "Epoch 95/120, Total Loss: 103.0164, Patch Loss: 8545.1647, Chr Loss: 43.1487, Chr Single Loss: 5184.8644\n",
      "Epoch 96/120, Total Loss: 103.0346, Patch Loss: 8538.9437, Chr Loss: 43.3330, Chr Single Loss: 5169.0525\n",
      "Epoch 97/120, Total Loss: 102.9003, Patch Loss: 8450.6988, Chr Loss: 43.8367, Chr Single Loss: 5114.5792\n",
      "Epoch 98/120, Total Loss: 104.9005, Patch Loss: 8576.1631, Chr Loss: 45.7991, Chr Single Loss: 5107.9611\n",
      "Epoch 99/120, Total Loss: 102.5165, Patch Loss: 8565.0674, Chr Loss: 43.2426, Chr Single Loss: 5123.5386\n",
      "Epoch 100/120, Total Loss: 102.4440, Patch Loss: 8425.8993, Chr Loss: 43.6004, Chr Single Loss: 5094.7813\n",
      "Epoch 101/120, Total Loss: 101.6931, Patch Loss: 8406.2589, Chr Loss: 42.6345, Chr Single Loss: 5117.2097\n",
      "Epoch 102/120, Total Loss: 100.4565, Patch Loss: 8397.9458, Chr Loss: 41.3335, Chr Single Loss: 5123.0505\n",
      "Epoch 103/120, Total Loss: 100.4530, Patch Loss: 8450.9583, Chr Loss: 41.7634, Chr Single Loss: 5074.8346\n",
      "Epoch 104/120, Total Loss: 99.9246, Patch Loss: 8427.9830, Chr Loss: 41.8419, Chr Single Loss: 5016.4778\n",
      "Epoch 105/120, Total Loss: 99.1958, Patch Loss: 8336.7492, Chr Loss: 41.3573, Chr Single Loss: 5000.6315\n",
      "Epoch 106/120, Total Loss: 99.0595, Patch Loss: 8370.8145, Chr Loss: 41.1298, Chr Single Loss: 5006.1021\n",
      "Epoch 107/120, Total Loss: 97.7021, Patch Loss: 8347.7364, Chr Loss: 40.5188, Chr Single Loss: 4933.0258\n",
      "Epoch 108/120, Total Loss: 99.1237, Patch Loss: 8341.3992, Chr Loss: 41.6448, Chr Single Loss: 4964.4861\n",
      "Epoch 109/120, Total Loss: 100.7396, Patch Loss: 8372.6237, Chr Loss: 42.1909, Chr Single Loss: 5069.0429\n",
      "Epoch 110/120, Total Loss: 99.6244, Patch Loss: 8403.6238, Chr Loss: 42.2621, Chr Single Loss: 4947.2633\n",
      "Epoch 111/120, Total Loss: 99.9419, Patch Loss: 8348.3722, Chr Loss: 43.1510, Chr Single Loss: 4896.5715\n",
      "Epoch 112/120, Total Loss: 100.3120, Patch Loss: 8443.5713, Chr Loss: 43.1910, Chr Single Loss: 4920.1277\n",
      "Epoch 113/120, Total Loss: 100.9801, Patch Loss: 8449.8573, Chr Loss: 43.4557, Chr Single Loss: 4960.1801\n",
      "Epoch 114/120, Total Loss: 100.1943, Patch Loss: 8562.5519, Chr Loss: 42.7325, Chr Single Loss: 4941.8297\n",
      "Epoch 115/120, Total Loss: 98.4103, Patch Loss: 8310.6558, Chr Loss: 41.2467, Chr Single Loss: 4935.5637\n",
      "Epoch 116/120, Total Loss: 98.0313, Patch Loss: 8435.4066, Chr Loss: 40.9999, Chr Single Loss: 4909.5603\n",
      "Epoch 117/120, Total Loss: 97.0050, Patch Loss: 8392.5281, Chr Loss: 40.4271, Chr Single Loss: 4867.8296\n",
      "Epoch 118/120, Total Loss: 98.4320, Patch Loss: 8371.9555, Chr Loss: 41.5890, Chr Single Loss: 4897.7105\n",
      "Epoch 119/120, Total Loss: 98.2718, Patch Loss: 8298.5611, Chr Loss: 42.2552, Chr Single Loss: 4823.0716\n",
      "Epoch 120/120, Total Loss: 98.6051, Patch Loss: 8414.1838, Chr Loss: 41.9878, Chr Single Loss: 4871.3263\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "\n",
    "pretrain_epoch = args.get(\"pretrain_epoch\", 150)\n",
    "epochs = args.get('epochs', 180)\n",
    "loss_ratio = args.get(\"loss_ratio\", 0.02)\n",
    "chr_single_ratio = args.get(\"chr_single_ratio\", 0.5)\n",
    "mask_ratio = args.get(\"mask_ratio\", 0.5)\n",
    "patience = args.get(\"patience\", 10)\n",
    "\n",
    "best_nmi = float(\"-inf\")\n",
    "best_loss = float(\"inf\")\n",
    "patience_count = 0\n",
    "\n",
    "if pretrain:\n",
    "    # chr_pretrain\n",
    "    optimizer_chr = torch.optim.Adam(model.parameters(), lr=args.get(\"learning rate\", 5e-4),\n",
    "                             weight_decay=args.get(\"weight_decay\", 0.0), betas=tuple(args.get(\"betas\", [0.9, 0.999])))\n",
    "    for epoch in range(pretrain_epoch):\n",
    "        model.train()\n",
    "        epoch_loss, epoch_chr_loss, epoch_chr_single_loss = 0, 0, 0\n",
    "        \n",
    "        for inputs in data_loader_train:\n",
    "            inputs = [item.to(device) for item in inputs]\n",
    "            optimizer_chr.zero_grad()\n",
    "            chr_loss, chr_single_loss = model.aepretrain(inputs)\n",
    "            loss = chr_loss  \n",
    "            loss.backward()\n",
    "            optimizer_chr.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_chr_loss += chr_loss.item()\n",
    "            if model.chr_single_loss:\n",
    "                epoch_chr_single_loss += chr_single_loss.item()\n",
    "            else:\n",
    "                epoch_chr_single_loss += chr_single_loss\n",
    "        \n",
    "        avg_loss = epoch_loss / len(data_loader_train)\n",
    "        print(f\"Pretrain Phase1 Epoch {epoch+1}/{pretrain_epoch}, Chr Loss: {epoch_chr_loss/len(data_loader_train):.4f}\")\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_count = 0\n",
    "            best_state = model.state_dict()\n",
    "        else:\n",
    "            patience_count += 1\n",
    "            if patience_count > patience:\n",
    "                print(\"Early stopping at pretrain phase 1\")\n",
    "                break\n",
    "    \n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    # patch_pretrain\n",
    "    optimizer_patch = torch.optim.Adam(model.parameters(), lr=args.get(\"learning rate\", 5e-4),\n",
    "                             weight_decay=args.get(\"weight_decay\", 0.0), betas=tuple(args.get(\"betas\", [0.9, 0.999])))\n",
    "    best_loss = float(\"inf\")\n",
    "    patience_count = 0\n",
    "    \n",
    "    for epoch in range(pretrain_epoch):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for inputs in data_loader_train:\n",
    "            inputs = [item.to(device) for item in inputs]\n",
    "            optimizer_patch.zero_grad()\n",
    "            chr_loss = model.patch_pretrain(inputs)\n",
    "            chr_loss.backward()\n",
    "            optimizer_patch.step()\n",
    "            epoch_loss += chr_loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(data_loader_train)\n",
    "        print(f\"Pretrain Phase2 Epoch {epoch+1}/{pretrain_epoch}, Patch Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_count = 0\n",
    "            best_state = model.state_dict()\n",
    "        else:\n",
    "            patience_count += 1\n",
    "            if patience_count > patience:\n",
    "                print(\"Early stopping at pretrain phase 2\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "print(f\"Start training for {args.get('epochs', 180)} epochs\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.get(\"learning rate\", 5e-4),\n",
    "                             weight_decay=args.get(\"weight_decay\", 0.0), betas=tuple(args.get(\"betas\", [0.9, 0.999])))\n",
    "cudnn.benchmark = True\n",
    "model.to(device)\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "patience_count = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    epoch_patch_loss = 0.0\n",
    "    epoch_chr_loss = 0.0\n",
    "    epoch_chr_single_loss = 0.0\n",
    "    \n",
    "    for inputs in data_loader_train:\n",
    "        inputs = [item.to(device) for item in inputs]\n",
    "        optimizer.zero_grad()\n",
    "        _, _, _, _, patch_loss, chr_loss, chr_single_loss = model(inputs, mask_ratio=mask_ratio)\n",
    "        \n",
    "\n",
    "        loss_combined = loss_ratio*patch_loss + (1-loss_ratio)*(1-chr_single_ratio)*chr_loss + (1-loss_ratio)*chr_single_ratio*chr_single_loss\n",
    "        loss_combined.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss_combined.item()\n",
    "        epoch_patch_loss += patch_loss.item()\n",
    "        epoch_chr_loss += chr_loss.item()\n",
    "        if chr_single_loss:\n",
    "            epoch_chr_single_loss += chr_single_loss.item()\n",
    "        else:\n",
    "            epoch_chr_single_loss += chr_single_loss\n",
    "    \n",
    "    avg_loss = running_loss / len(data_loader_train)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Total Loss: {avg_loss:.4f}, Patch Loss: {epoch_patch_loss/len(data_loader_train):.4f}, Chr Loss: {epoch_chr_loss/len(data_loader_train):.4f}, Chr Single Loss: {epoch_chr_single_loss/len(data_loader_train):.4f}\")\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_count = 0\n",
    "        best_state = model.state_dict()\n",
    "    else:\n",
    "        patience_count += 1\n",
    "        if patience_count > patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "\n",
    "model.load_state_dict(best_state)\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " UserWarning:/home/wuxiaoqing/anaconda3/envs/vit/lib/python3.9/site-packages/umap/umap_.py:1943: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === UMAP ===\n",
    "model.eval()\n",
    "cell_embed_matrix = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in data_loader_test:\n",
    "        result = []\n",
    "        inputs = [item.to(device) for item in inputs]\n",
    "        x, attn_mask, all_patches, token_class = model.forward_encoder(inputs)\n",
    "        chr_cls_index = np.where(token_class == 1)[0]\n",
    "        chr_cls_tokens = x[:,chr_cls_index, :]\n",
    "        chr_cls_tokens = chr_cls_tokens.view(chr_cls_tokens.shape[0], -1)\n",
    "        cell_embed = model.latent_layer(chr_cls_tokens)\n",
    "        cell_embed = model.pred_hidden(cell_embed)\n",
    "        cell_embed = torch.nn.functional.gelu(cell_embed)\n",
    "        cell_embed = np.squeeze(cell_embed.cpu().numpy())\n",
    "        cell_embed_matrix.append(cell_embed)\n",
    "cell_embed_matrix = np.vstack(cell_embed_matrix)\n",
    "\n",
    "\n",
    "latent_cell_matrix = np.vstack(cell_embed_matrix)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "latent_std = scaler.fit_transform(latent_cell_matrix)\n",
    "umap_result = UMAP(n_components=2, random_state=42).fit_transform(latent_std)\n",
    "\n",
    "# ç»˜å›¾\n",
    "plt.figure(figsize=(5,4))\n",
    "sorted_categories = sorted(set(labels))\n",
    "color_list = sns.color_palette(\"tab20\", n_colors=len(sorted_categories))\n",
    "sns.scatterplot(x=umap_result[:, 0], y=umap_result[:, 1], s=10,\n",
    "                hue=labels, hue_order=sorted_categories, palette=color_list)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', markerscale=3)\n",
    "plt.title('UMAP of Cell Embeddings')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
